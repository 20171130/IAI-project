{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "from utilities.data_structures.Config import Config\n",
    "from agents.DQN_agents.DDQN import DDQN\n",
    "from agents.DQN_agents.DQN_With_Fixed_Q_Targets import DQN_With_Fixed_Q_Targets\n",
    "\n",
    "config = Config()\n",
    "config.seed = 1\n",
    "config.environment = gym.make(\"CartPole-v0\")\n",
    "config.num_episodes_to_run = 450\n",
    "config.file_to_save_data_results = \"results/data_and_graphs/Cart_Pole_Results_Data.pkl\"\n",
    "config.file_to_save_results_graph = \"results/data_and_graphs/Cart_Pole_Results_Graph.png\"\n",
    "config.show_solution_score = False\n",
    "config.visualise_individual_results = False\n",
    "config.visualise_overall_agent_results = True\n",
    "config.standard_deviation_results = 1.0\n",
    "config.runs_per_agent = 1\n",
    "config.use_GPU = True\n",
    "config.overwrite_existing_results_file = False\n",
    "config.randomise_random_seed = True\n",
    "config.save_model = False\n",
    "\n",
    "\n",
    "config.hyperparameters = {\n",
    "    \"DQN_Agents\": {\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"batch_size\": 256,\n",
    "        \"buffer_size\": 40000,\n",
    "        \"epsilon\": 1.0,\n",
    "        \"epsilon_decay_rate_denominator\": 1,\n",
    "        \"discount_rate\": 0.99,\n",
    "        \"tau\": 0.01,\n",
    "        \"alpha_prioritised_replay\": 0.6,\n",
    "        \"beta_prioritised_replay\": 0.1,\n",
    "        \"incremental_td_error\": 1e-8,\n",
    "        \"update_every_n_steps\": 1,\n",
    "        \"learning_iterations\": 1,\n",
    "        \"linear_hidden_units\": [30, 15],\n",
    "        \"final_layer_activation\": \"None\",\n",
    "        \"batch_norm\": False,\n",
    "        \"gradient_clipping_norm\": 0.7,\n",
    "        \"clip_rewards\": False\n",
    "    },\n",
    "    \"Stochastic_Policy_Search_Agents\": {\n",
    "        \"policy_network_type\": \"Linear\",\n",
    "        \"noise_scale_start\": 1e-2,\n",
    "        \"noise_scale_min\": 1e-3,\n",
    "        \"noise_scale_max\": 2.0,\n",
    "        \"noise_scale_growth_factor\": 2.0,\n",
    "        \"stochastic_action_decision\": False,\n",
    "        \"num_policies\": 10,\n",
    "        \"episodes_per_policy\": 1,\n",
    "        \"num_policies_to_keep\": 5,\n",
    "        \"clip_rewards\": False\n",
    "    },\n",
    "    \"Policy_Gradient_Agents\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"linear_hidden_units\": [20, 20],\n",
    "        \"final_layer_activation\": \"SOFTMAX\",\n",
    "        \"learning_iterations_per_round\": 5,\n",
    "        \"discount_rate\": 0.99,\n",
    "        \"batch_norm\": False,\n",
    "        \"clip_epsilon\": 0.1,\n",
    "        \"episodes_per_learning_round\": 4,\n",
    "        \"normalise_rewards\": True,\n",
    "        \"gradient_clipping_norm\": 7.0,\n",
    "        \"mu\": 0.0, #only required for continuous action games\n",
    "        \"theta\": 0.0, #only required for continuous action games\n",
    "        \"sigma\": 0.0, #only required for continuous action games\n",
    "        \"epsilon_decay_rate_denominator\": 1.0,\n",
    "        \"clip_rewards\": False\n",
    "    },\n",
    "\n",
    "    \"Actor_Critic_Agents\":  {\n",
    "\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"linear_hidden_units\": [20, 10],\n",
    "        \"final_layer_activation\": [\"SOFTMAX\", None],\n",
    "        \"gradient_clipping_norm\": 5.0,\n",
    "        \"discount_rate\": 0.99,\n",
    "        \"epsilon_decay_rate_denominator\": 1.0,\n",
    "        \"normalise_rewards\": True,\n",
    "        \"exploration_worker_difference\": 2.0,\n",
    "        \"clip_rewards\": False,\n",
    "\n",
    "        \"Actor\": {\n",
    "            \"learning_rate\": 0.0003,\n",
    "            \"linear_hidden_units\": [64, 64],\n",
    "            \"final_layer_activation\": \"Softmax\",\n",
    "            \"batch_norm\": False,\n",
    "            \"tau\": 0.005,\n",
    "            \"gradient_clipping_norm\": 5,\n",
    "            \"initialiser\": \"Xavier\"\n",
    "        },\n",
    "\n",
    "        \"Critic\": {\n",
    "            \"learning_rate\": 0.0003,\n",
    "            \"linear_hidden_units\": [64, 64],\n",
    "            \"final_layer_activation\": None,\n",
    "            \"batch_norm\": False,\n",
    "            \"buffer_size\": 1000000,\n",
    "            \"tau\": 0.005,\n",
    "            \"gradient_clipping_norm\": 5,\n",
    "            \"initialiser\": \"Xavier\"\n",
    "        },\n",
    "\n",
    "        \"min_steps_before_learning\": 400,\n",
    "        \"batch_size\": 256,\n",
    "        \"discount_rate\": 0.99,\n",
    "        \"mu\": 0.0, #for O-H noise\n",
    "        \"theta\": 0.15, #for O-H noise\n",
    "        \"sigma\": 0.25, #for O-H noise\n",
    "        \"action_noise_std\": 0.2,  # for TD3\n",
    "        \"action_noise_clipping_range\": 0.5,  # for TD3\n",
    "        \"update_every_n_steps\": 1,\n",
    "        \"learning_updates_per_learning_session\": 1,\n",
    "        \"automatically_tune_entropy_hyperparameter\": True,\n",
    "        \"entropy_term_weight\": None,\n",
    "        \"add_extra_noise\": False,\n",
    "        \"do_evaluation_iterations\": True\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hyperparameters = config.hyperparameters[\"DQN_Agents\"]\n",
    "agent = DQN_With_Fixed_Q_Targets(config)\n",
    "game_scores, rolling_scores, time_taken = agent.run_n_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDQN 330"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
